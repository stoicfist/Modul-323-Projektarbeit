\documentclass[a4paper,11pt]{article}

% --------------------
% Pakete
% --------------------
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{parskip}
\usepackage{xcolor}
\usepackage{tocloft}
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=blue,     % interne Links (Inhaltsverzeichnis etc.)
  urlcolor=blue,      % URLs
  citecolor=blue      % Literaturzitate (falls du später welche hast)
}

\geometry{margin=2.5cm}
\onehalfspacing
\setlength{\parindent}{0pt}
\setcounter{tocdepth}{4}


% --- Darkmode Farben für Code ---
\definecolor{codebg}{HTML}{0B0F14}      % sehr dunkles Blau-Schwarz
\definecolor{codefg}{HTML}{E6D5B8}      % beige
\definecolor{codekw}{HTML}{7AA2F7}      % blau (Keywords)
\definecolor{codestr}{HTML}{E0AF68}     % orange/beige (Strings)
\definecolor{codecom}{HTML}{7F8C8D}     % grau (Kommentare)
\definecolor{codenum}{HTML}{56687A}     % grau-blau (Zeilennummern)
\definecolor{codeframe}{HTML}{1F2A37}   % Rahmen

% --------------------
% Code-Style
% --------------------
\lstset{
  language=Python,
  basicstyle=\ttfamily\small\color{codefg},
  backgroundcolor=\color{codebg},
  keywordstyle=\bfseries\color{codekw},
  stringstyle=\color{codestr},
  commentstyle=\itshape\color{codecom},
  numbers=left,
  numberstyle=\tiny\color{codenum},
  stepnumber=1,
  numbersep=8pt,
  frame=single,
  rulecolor=\color{codeframe},
  breaklines=true,
  breakatwhitespace=true,
  showstringspaces=false,
  tabsize=4,
  keepspaces=true
}

% --------------------
% Dokument
% --------------------
\begin{document}

\begin{titlepage}
    \centering
    \vspace*{1.8cm}

    {\Large Modul M323 – Funktionales Programmieren\par}
    \vspace{1cm}

    \rule{0.8\textwidth}{0.4pt}\par
    \vspace{0.6cm}

    {\Huge\bfseries Bank Marketing Data\par}
    \vspace{0.2cm}
    {\LARGE Kundenanalyse \& Abschlussprognose\par}

    \vspace{0.6cm}
    \rule{0.8\textwidth}{0.4pt}\par

    \vspace{2cm}

    {\large Projekt-Dokumentation\par}
    \vspace{2cm}

    \renewcommand{\arraystretch}{1.3}
    \begin{tabular}{ll}
        \textbf{Autoren:} & Peter Ngo, Alex Uscata \\
        \textbf{Klasse:}  & INA 23A \\
        \textbf{Dozent:}  & Dieter Kopp \\
        \textbf{Datum:}   & \today
    \end{tabular}

    \vfill
\end{titlepage}

\tableofcontents
\newpage

% ======================================================
\section{Einleitung}

Im Rahmen des Moduls M323 – Funktionales Programmieren wird in diesem Projekt
eine Datenanalyse einer Bank-Marketingkampagne umgesetzt.
Ziel ist es, eine imperativ geschriebene Lösung mit einer funktional
refaktorierten Version zu vergleichen und die Vor- sowie Nachteile
funktionaler Sprachelemente praxisnah zu evaluieren.

Als Datengrundlage dient ein realitätsnaher Datensatz einer portugiesischen
Bank, welcher Kundendaten sowie den Erfolg einer Marketingkampagne enthält.
Beide Programmversionen erzeugen denselben Output, unterscheiden sich jedoch
grundlegend in der Programmierweise.

\medskip
Die verwendeten Daten werden in Abschnitt~\ref{sec:datengrundlage}
beschrieben. Der Einfluss funktionaler Sprachelemente wird anschließend
im Refactoring-Vergleich in Abschnitt~\ref{sec:refactoring} analysiert.

% ======================================================
\section{Wahl der imperativen Programmiersprache}

\subsection{Begründung der Sprachwahl}

Für dieses Projekt wurde die Programmiersprache \textbf{Python} gewählt.
Python eignet sich besonders gut für Datenanalysen, da die Sprache:

\begin{itemize}
    \item leicht lesbar und verständlich ist
    \item imperative Programmierung vollständig unterstützt
    \item funktionale Sprachelemente integriert anbietet
    \item häufig im beruflichen Umfeld eingesetzt wird
\end{itemize}

Da Python sowohl imperative als auch funktionale Konzepte vereint, ist die
Sprache ideal geeignet, um beide Programmierparadigmen direkt miteinander
zu vergleichen.

\subsection{Unterstützte funktionale Elemente in Python}

Python ist keine rein funktionale Sprache, bietet jedoch zahlreiche
funktionale Sprachelemente aus der Standardbibliothek:

\begin{itemize}
    \item \texttt{map()} – Transformation von Daten
    \item \texttt{filter()} – Selektion von Elementen
    \item \texttt{reduce()} (aus \texttt{functools}) – Aggregation
    \item Lambda-Funktionen
    \item List Comprehensions
    \item Unveränderliche Datentypen (z.\,B. Tupel)
\end{itemize}

Diese Elemente ermöglichen eine deklarative und kompakte Beschreibung
von Datenverarbeitungslogik.

\subsection{Funktionale Sprachelemente in Python – Detailanalyse}

Neben den grundlegenden funktionalen Sprachelementen weist Python im Vergleich zu
rein funktionalen Sprachen sowohl konzeptionelle Stärken als auch Einschränkungen auf.

\paragraph{Higher-Order Functions}

Python unterstützt Higher-Order Functions nativ, allerdings mit einigen
charakteristischen Besonderheiten:

\begin{itemize}
    \item \texttt{map()} und \texttt{filter()} liefern Iteratoren und arbeiten damit
    lazily. Dies spart Speicher, verhindert jedoch ein mehrfaches Durchlaufen
    derselben Daten ohne explizite Materialisierung (z.\,B. mittels \texttt{list()}).

    \item \texttt{reduce()} wurde seit Python~3 in das Modul \texttt{functools}
    ausgelagert. Diese Designentscheidung reflektiert, dass in Python explizite
    Schleifen oder spezielle Aggregatfunktionen (\texttt{sum}, \texttt{min}, \texttt{max})
    häufig als besser lesbar angesehen werden.
\end{itemize}

Im Projekt wird \texttt{reduce()} dennoch bewusst eingesetzt, um die funktionale
Aggregation explizit sichtbar zu machen (z.\,B. bei der Gruppierung von Datensätzen
oder der Berechnung von Buckets).

\paragraph{Limitierungen gegenüber Haskell}

Im Vergleich zu rein funktionalen Sprachen wie Haskell weist Python mehrere
Einschränkungen auf:

\begin{itemize}
    \item Keine Tail-Call-Optimierung: Rekursive Funktionen sind durch eine
    begrenzte Rekursionstiefe (ca. 1000 Aufrufe) eingeschränkt und daher für
    viele funktionale Muster ungeeignet.

    \item Mutable Default Arguments können unbeabsichtigte Seiteneffekte
    verursachen und widersprechen dem Prinzip der funktionalen Reinheit.

    \item Kein echtes Pattern Matching auf Funktionsebene; erst ab Python~3.10
    steht mit \texttt{match/case} ein strukturelles Matching für Kontrollflüsse zur Verfügung,
    das jedoch nicht die Ausdrucksstärke funktionaler Pattern Matches erreicht.
\end{itemize}

Damit wird deutlich, dass Python funktionale Konzepte eher als ergänzende
Sprachmittel bereitstellt, nicht jedoch als tragendes Paradigma erzwingt.
Die funktionale Programmierung in Python beruht daher stärker auf
Programmierdisziplin als auf sprachlicher Absicherung durch den Compiler.


\subsubsection{Kurzbeispiele der funktionalen Elemente}

\begin{lstlisting}[language=Python]
# map: Transformation
list(map(lambda x: x*x, [1,2,3]))      # -> [1,4,9]

# filter: Selektion
list(filter(lambda x: x > 2, [1,2,3])) # -> [3]

# reduce: Aggregation
from functools import reduce
reduce(lambda acc, x: acc + x, [1,2,3], 0)  # -> 6
\end{lstlisting}

Diese funktionalen Konzepte werden im Projekt konkret eingesetzt für:
\begin{itemize}
  \item Filterung von Datensätzen über Prädikatfunktionen (\texttt{apply\_filters})
  \item Gruppierung von Daten mittels \texttt{reduce} (\texttt{group\_by\_key})
  \item Numerische Transformationen und Aggregationen (\texttt{mean}, ANOVA)
\end{itemize}

% ======================================================
\section{Datengrundlage}
\label{sec:datengrundlage}

\subsection{Beschreibung des Datensatzes}

Als Datengrundlage dient ein Bank-Marketing-Datensatz einer portugiesischen Bank,
der auf einer öffentlich dokumentierten Bank-Marketing-Studie basiert
(vgl.~\cite{moro2011}).
Der Datensatz enthält Kundendaten aus einer Marketingkampagne sowie eine Zielvariable,
welche angibt, ob ein Produktabschluss erfolgt ist (\texttt{complete = yes/no}).

Die Daten liegen in Form einer CSV-Datei vor und wurden im Projekt ausschließlich
lesend verwendet.

\subsection{Hauptdimensionen}

Der Datensatz lässt sich in folgende Hauptdimensionen einteilen:

\begin{itemize}
    \item \textbf{Demografie:} Alter (\texttt{age}), Bildungsstand (\texttt{education}), Familienstand (\texttt{marital})
    \item \textbf{Finanzen:} Kontostand (\texttt{balance})
    \item \textbf{Kontaktdaten:} Gesprächsdauer (\texttt{duration})
    \item \textbf{Ergebnisvariable:} Produktabschluss (\texttt{complete})
\end{itemize}

\subsection{Verwendete Variablen}

Im Projekt werden unter anderem folgende Variablen verwendet:

\begin{itemize}
    \item \texttt{age} (numerisch)
    \item \texttt{job} (kategorisch)
    \item \texttt{marital} (kategorisch)
    \item \texttt{education} (kategorisch)
    \item \texttt{balance} (numerisch)
    \item \texttt{housing} (binär)
    \item \texttt{loan} (binär)
    \item \texttt{duration} (numerisch)
    \item \texttt{complete} (binär, Zielvariable)
\end{itemize}

\subsection{Herkunft des Datensatzes und Abgrenzung}

Der im Projekt verwendete Bank-Marketing-Datensatz stammt ursprünglich aus
einer universitären Lehrveranstaltung zur multivariaten Datenanalyse an der
Universität Basel (vgl.~\cite{unibas-assignment}).
Der Datensatz wurde im Rahmen eines Assignments zur statistischen Auswertung
von Bank-Marketingkampagnen eingesetzt und basiert auf realitätsnahen,
vorverarbeiteten Kundendaten einer portugiesischen Bank.

Die Aufgabenstellung des ursprünglichen Assignments umfasste unter anderem
Varianzanalysen, logaritmische Transformationen sowie Klassifikationsverfahren.
In diesem Projekt wird der Datensatz jedoch ausschließlich als Datengrundlage
verwendet und in einen neuen Kontext übertragen.

Die Zielsetzung dieses Projekts unterscheidet sich bewusst von der ursprünglichen
universitären Aufgabenstellung:
Der Fokus liegt nicht auf statistischer Modellbildung oder Inferenz,
sondern auf dem Vergleich imperativer und funktionaler Programmierparadigmen
im Sinne des Moduls M323 – Funktionales Programmieren.

% ======================================================
\section{Projektantrag}

\subsection{Ausgangslage}

Während einer Marketingkampagne hat eine Bank verschiedene Kundendaten
erfasst. Der Datensatz liegt in Form einer CSV-Datei vor und ist nicht
direkt für Analysen aufbereitet.

Ziel ist es, relevante Kennzahlen zu berechnen, Kundengruppen zu vergleichen
und statistische Zusammenhänge zu untersuchen.

\subsection{Zielsetzung}

Das Projekt verfolgt folgende Ziele:

\begin{itemize}
    \item Analyse der Erfolgsquote der Marketingkampagne
    \item Vergleich verschiedener Kundengruppen
    \item Umsetzung einer imperativen Version (V1.0)
    \item Refactoring in eine funktionale Version (V2.0)
    \item Vergleich beider Ansätze hinsichtlich Lesbarkeit und Wartbarkeit
\end{itemize}

\subsection{Projektumfang}

Das Projekt umfasst:

\begin{itemize}
    \item Einlesen und Verarbeiten eines CSV-Datensatzes
    \item Textbasierte Konsolenausgabe
    \item Keine externen Bibliotheken
    \item Umsetzung in Python; Ausführung und Dokumentation der Experimente in einem Jupyter Notebook (Tooling).
\end{itemize}

% ======================================================
\section{Programmausgabe}

Beide Versionen des Programms erzeugen denselben Output.
Die Ausgabe erfolgt textbasiert in der Konsole.

\subsection{Beispielhafter Output}

Das folgende Beispiel zeigt die Konsolenausgabe der Auswertungsfunktion
\textit{Group by Education} (Menüoption 5).
Dabei werden alle Datensätze nach Bildungsniveau gruppiert und aggregierte
Kennzahlen berechnet, darunter die Anzahl der Kunden, das durchschnittliche
Alter, der durchschnittliche Kontostand sowie die Erfolgsquote der
Marketingkampagne.

Die dargestellte Ausgabe wird sowohl von Version 1.0 (imperative Umsetzung)
als auch von Version 2.0 (funktionale Umsetzung) identisch erzeugt.

\begin{verbatim}
                           GROUP BY EDUCATION
========================================================================
education | count | avg(age) | avg(balance) | success
----------+-------+----------+--------------+--------
primary   |  1002 |     49.0 |      1970.88 |   48.3%
secondary |  3815 |     40.7 |      1709.54 |   52.2%
tertiary  |  2657 |     39.7 |      2404.61 |   62.5%

ANOVA F-Wert: 41.93 (df=2,7471)
\end{verbatim}
\end{lstlisting}

\textit{Hinweis:} Version 1.0 (imperativ) und Version 2.0 (funktional)
liefern identische Resultate. Weitere exemplarische Konsolenausgaben zu anderen
Menüoptionen befinden sich im Appendix (vgl. Abschnitt~\ref{sec:appendix-output}).

\subsection{Validierung der Resultate}
Die automatisierten Tests befinden sich im Verzeichnis \texttt{tests/} und können
direkt über die Kommandozeile ausgeführt werden:

\begin{verbatim}
python test_outputs.py
\end{verbatim}

Zur Validierung wurden mehrere automatisierte Tests implementiert, welche die
funktionale und die imperative Implementierung systematisch miteinander
vergleichen. Ziel dieser Tests ist es, sicherzustellen, dass beide
Programmversionen trotz unterschiedlicher Programmierparadigmen identische
inhaltliche Resultate liefern.

Konkret wurden folgende Aspekte überprüft:
\begin{itemize}
    \item Vergleich der Gruppierungsresultate (\textit{Group by Education}):
    Gruppennamen, Gruppengrößen, durchschnittliches Alter, durchschnittlicher
    Kontostand sowie Erfolgsquoten stimmen in beiden Implementierungen überein.
    \item Vergleich des berechneten ANOVA-F-Werts inklusive der Freiheitsgrade
    ($df_{between}$ und $df_{within}$).
    \item Invarianzprüfung: Die Summe der Gruppengrößen entspricht stets der
    Gesamtanzahl der Datensätze, und alle Erfolgsquoten liegen im gültigen
    Wertebereich $[0,1]$.
    \item Determinismus: Mehrfache Ausführungen mit identischen Eingabedaten
    liefern in beiden Implementierungen stets exakt dieselben Resultate.
    \item Behandlung von Randfällen: Für unzureichende Datengrundlagen (z.\,B.
    leere Datensätze oder nur eine vorhandene Gruppe) liefert die ANOVA-Funktion
    korrekt den Wert \texttt{None}.
\end{itemize}

Alle Tests wurden erfolgreich ausgeführt und bestätigen die inhaltliche
Äquivalenz der funktionalen und imperativen Version. Damit ist sichergestellt,
dass die Unterschiede zwischen beiden Programmen ausschließlich in der
Programmstruktur und im verwendeten Paradigma liegen, nicht jedoch in den
berechneten Ergebnissen.

\subsection{Interpretation und statistische Einordnung}

Die Ergebnisse zeigen, dass der durchschnittliche Kontostand sowie die
Erfolgsquote mit steigendem Bildungsniveau zunehmen.
Kunden mit tertiärer Ausbildung weisen sowohl den höchsten durchschnittlichen
Kontostand als auch die höchste Erfolgsquote auf.

Zur Bewertung der Unterschiede zwischen den Bildungsgruppen wird eine
einfaktorielle Varianzanalyse (ANOVA) verwendet.
Der ANOVA-F-Wert beschreibt das Verhältnis der Varianz zwischen den Gruppen
zur Varianz innerhalb der Gruppen.
Ein hoher F-Wert deutet darauf hin, dass sich die Mittelwerte der Gruppen
deutlich voneinander unterscheiden und die Varianz zwischen den
Bildungsgruppen größer ist als die Varianz innerhalb der Gruppen.

Die angegebenen Freiheitsgrade ($df$) geben an, wie viele unabhängige
Informationen in die Berechnung eingeflossen sind.
Dabei beschreibt $df_{between}$ die Anzahl der verglichenen Gruppen minus eins,
während $df_{within}$ die Streuung der Werte innerhalb der Gruppen widerspiegelt
\cite{montgomery2017}.

Die Varianzanalyse wird in diesem Projekt ausschließlich deskriptiv verwendet.
Der F-Wert dient hier als Maßzahl zur Beschreibung der Stärke von
Unterschieden zwischen den Gruppen und nicht als formale Entscheidungsregel
im Sinne eines statistischen Signifikanztests.
Auf die Berechnung von p-Werten und eine formale Hypothesenprüfung wird daher
bewusst verzichtet.

% ======================================================
\section{Refactoring: Vergleich Version 1.0 vs. Version 2.0}
\label{sec:refactoring}

Beide Programmversionen implementieren dieselben Produktfunktionen und erzeugen identische Resultate,
unterscheiden sich jedoch in der Umsetzung:
Version 1.0 verwendet primär imperative Sprachmittel (Schleifen, Hilfsvariablen, schrittweiser Aufbau
von Resultaten), während Version 2.0 die gleiche Logik mit funktionalen Sprachmitteln
(z.\,B. \texttt{map}, \texttt{filter}, \texttt{reduce}, Lambdas) ausdrückt.

\subsection{Konkrete Beispiele aus dem Projekt}

\subsubsection{Beispiel A: Filtern von Datensätzen}
In Version 1.0 wird die Filterlogik mit einer Schleife und \texttt{continue} umgesetzt.
In Version 2.0 wird dieselbe Logik deklarativ als Prädikatfunktion formuliert und per \texttt{filter} angewendet.

\paragraph{Imperative Umsetzung (Version 1.0)}\mbox{}

\begin{lstlisting}[
    language=Python,
    numbers=left,
    firstnumber=68,
    caption={Imperative Filterung mittels Schleifen und Kontrollfluss aus \texttt{imperative\_version.py}},
    label={lst:apply_filters_imperative}
  ]

def apply_filters(data: List[Dict[str, Any]], housing: Optional[bool], loan: Optional[bool], balance_gt: Optional[float]) -> List[Dict[str, Any]]:

    out: List[Dict[str, Any]] = []
    for row in data:
        if housing is not None and row.get("housing") is not housing:
            continue
        if loan is not None and row.get("loan") is not loan:
            continue
        bal = row.get("balance")
        if balance_gt is not None:
            if bal is None or bal <= balance_gt:
                continue
        out.append(row)
    return out
\end{lstlisting}


\paragraph{Funktionale Umsetzung (Version 2.0)}\mbox{}

\begin{lstlisting}[
    language=Python,
    numbers=left,
    firstnumber=139,
    caption={Funktionale Filterung mittels Prädikatfunktion und \texttt{filter} aus \texttt{functional\_version.py}},
    label={lst:apply_filters_functional}
  ]

def apply_filters(data: List[Dict[str, Any]], housing: Optional[bool], loan: Optional[bool], balance_gt: Optional[float]) -> List[Dict[str, Any]]:

    def pred(row: Dict[str, Any]) -> bool:
        if housing is not None and row.get("housing") is not housing:
            return False
        if loan is not None and row.get("loan") is not loan:
            return False
        if balance_gt is not None:
            bal = row.get("balance")
            if bal is None or bal <= balance_gt:
                return False
        return True

    return list(filter(pred, data))
\end{lstlisting}

Die beiden Codeausschnitte zeigen die Umsetzung derselben Filterlogik in
imperativer und funktionaler Form.
In der imperativen Version (Listing~\ref{lst:apply_filters_imperative}) wird der
Datensatz explizit mit einer Schleife durchlaufen, und die Filterbedingungen
werden über Kontrollflussanweisungen wie \texttt{continue} realisiert.
Zwischenergebnisse werden dabei in einer veränderlichen Liste gesammelt.

In der funktionalen Version (Listing~\ref{lst:apply_filters_functional}) wird die
Filterlogik in einer separaten Prädikatfunktion gekapselt und anschließend
deklarativ mit der Higher-Order-Funktion \texttt{filter} auf den gesamten Datensatz
angewendet.
Dadurch entfällt expliziter Kontrollfluss, und die Logik beschreibt direkt,
welche Elemente beibehalten werden sollen, anstatt wie iteriert werden muss.

\subsubsection{Beispiel B: Gruppierung mit \texttt{reduce} (Group by)}

Für mehrere Auswertungen (z.\,B. \textit{Group by Education}) müssen Datensätze nach einem Feldwert
gruppiert werden. In Version 1.0 wird dafür schrittweise ein Dictionary aufgebaut und jede Zeile
wird in eine veränderliche Liste eingefügt.
Version 2.0 formuliert dieselbe Operation als funktionale Faltung (\texttt{reduce}), wobei der
Akkumulator als unveränderliche Struktur behandelt und bei jedem Schritt neu erzeugt wird.

\paragraph{Imperative Umsetzung (Version 1.0)}\mbox{}

\begin{lstlisting}[
    language=Python,
    numbers=left,
    firstnumber=234,
    caption={Imperative Gruppierung mit Schleifen und veränderlichem Zustand aus \texttt{imperative\_version.py}},
    label={lst:group_by_imperative}
  ]

def group_by_key(data: List[Dict[str, Any]], key: str) -> Dict[str, List[Dict[str, Any]]]:

      groups: Dict[str, List[Dict[str, Any]]] = {}
      for row in data:
          k = row.get(key)
          k_str = "" if k is None else str(k)
          if k_str not in groups:
              groups[k_str] = []
          groups[k_str].append(row)
      return groups
\end{lstlisting}

\paragraph{Funktionale Umsetzung (Version 2.0)}\mbox{}

\begin{lstlisting}[
    language=Python,
    numbers=left,
    firstnumber=424,
    caption={Funktionale Gruppierung mit \texttt{reduce} aus \texttt{functional\_version.py}},
    label={lst:group_by_reduce}
  ]

def group_by_key(data: List[Dict[str, Any]], key: str) -> Dict[str, Tuple[Dict[str, Any], ...]]:

    def add(acc: Dict[str, Tuple[Dict[str, Any], ...]], row: Dict[str, Any]) -> Dict[str, Tuple[Dict[str, Any], ...]]:
         k = row.get(key)
         k_str = "" if k is None else str(k)
         existing_group = acc.get(k_str, ())
         new_group = existing_group + (row,)
         return {**acc, k_str: new_group}

    return reduce(add, data, {})
\end{lstlisting}

Die folgenden Listings zeigen dieselbe Funktionalität zur Gruppierung von Datensätzen,
einmal in imperativer (Listing~\ref{lst:group_by_imperative}) und einmal in funktionaler
Umsetzung (Listing~\ref{lst:group_by_reduce}). Beide Ausschnitte stammen aus den
jeweiligen Implementierungsdateien und wurden zur besseren Vergleichbarkeit
isoliert dargestellt.

Die imperative Variante arbeitet mit veränderlichen Datenstrukturen (Dictionary und Listen) und
verändert diese schrittweise.
Die funktionale Variante beschreibt denselben Prozess als Abbildung von \emph{Akkumulator + Element}
auf einen neuen Akkumulator und vermeidet dabei mutierende Operationen.
Dadurch wird die Gruppierungslogik deklarativer und lässt sich direkt für mehrere Auswertungen
wiederverwenden (z.\,B. Bildung, Beruf oder Familienstand).


\subsubsection{Beispiel C: Transformation und Aggregation numerischer Werte (\texttt{map} und \texttt{sum})}

Die Berechnung des arithmetischen Mittels zeigt exemplarisch, wie numerische
Transformation und Aggregation in der funktionalen Version ohne explizite
Schleifen oder veränderliche Akkumulatoren umgesetzt werden können.
Zunächst werden alle Werte mittels \texttt{map} in Gleitkommazahlen transformiert,
anschließend erfolgt die Aggregation über \texttt{sum}.

\paragraph{Imperative Umsetzung (Version 1.0)}\mbox{}

\begin{lstlisting}[
    language=Python,
    numbers=left,
    firstnumber=117,
    caption={Imperative Berechnung des arithmetischen Mittels mit expliziter Schleife aus \texttt{imperative\_version.py}},
    label={lst:mean_imperative}
  ]

def mean(values: List[float]) -> Optional[float]:

    if not values:
        return None
    s = 0.0
    n = 0
    for v in values:
        s += float(v)
        n += 1
    if n == 0:
        return None
    return s / float(n)
\end{lstlisting}

\paragraph{Funktionale Umsetzung (Version 2.0)}\mbox{}

\begin{lstlisting}[
    language=Python,
    numbers=left,
    firstnumber=294,
    caption={Funktionale Berechnung des arithmetischen Mittels mit \texttt{map} und \texttt{sum} aus \texttt{functional\_version.py}},
    label={lst:mean_functional}
  ]

def mean(values: List[float]) -> Optional[float]:

    return (sum(map(float, values)) / float(len(values))) if values else None
\end{lstlisting}

Die beiden Listings zeigen die Berechnung des arithmetischen Mittels einmal in
imperativer und einmal in funktionaler Form.
In der imperativen Version (Listing~\ref{lst:mean_imperative}) wird ein veränderlicher
Akkumulator (\texttt{s}) sowie ein expliziter Zähler (\texttt{n}) verwendet, die innerhalb
einer Schleife schrittweise aktualisiert werden.

In der funktionalen Version (Listing~\ref{lst:mean_functional}) wird dieselbe Berechnung
deklarativ formuliert: Die Transformation der Werte erfolgt über \texttt{map}, die
Aggregation über \texttt{sum}. Ein expliziter Schleifenindex oder ein veränderlicher
Zwischenzustand ist nicht notwendig. Dadurch entspricht der Code direkt der
mathematischen Definition des Mittelwerts und ist kompakter sowie leichter zu lesen.

\subsubsection{Zusammenfassung der Unterschiede}

\begin{itemize}
  \item \textbf{Lesbarkeit:} Version 2.0 ist kompakter und beschreibt häufig \emph{was} berechnet wird, statt \emph{wie}.
  \item \textbf{Wartbarkeit:} Wiederverwendbare Hilfsfunktionen (Prädikate, Mapping-Funktionen) reduzieren Duplikation.
  \item \textbf{Fehleranfälligkeit:} Weniger mutable Zwischenzustände und weniger Hilfsvariablen verringern typische Fehlerquellen.
\end{itemize}

% ======================================================
\section{Fazit}

\subsection{Nutzen funktionaler Elemente}

Der Einsatz funktionaler Sprachelemente hat in diesem Projekt mehrere
Vorteile gebracht. Insbesondere Filter- und Transformationsoperationen
konnten kompakter und klarer formuliert werden.

\subsection{Vereinfachung durch Refactoring}

Im Vergleich zur imperativen Version ist die funktionale Umsetzung
nicht zwingend kürzer, jedoch stärker strukturiert.
Verschachtelte Schleifen und mutable Hilfsvariablen werden häufig
durch deklarative Ausdrücke ersetzt, welche Transformation,
Selektion und Aggregation klar voneinander trennen.
Der Fokus liegt somit weniger auf der reinen Code-Länge,
sondern auf Lesbarkeit, Wartbarkeit und einer geringeren
Fehleranfälligkeit.

\subsection{Bewusste Designentscheidungen}

Im Rahmen der Transformation numerischer Variablen wurden bewusst unterschiedliche
mathematische Abbildungen eingesetzt.
Neben einer fachlich realistischen Transformation mittels Logarithmus
\( \log(\text{balance}) \) wurde zusätzlich eine einfache quadratische Transformation
\( \text{balance}^2 + 1 \) verwendet.

Der Logarithmus ist insbesondere im wirtschaftlichen Kontext sinnvoll, da er
rechtsschiefe Verteilungen reduziert und Ausreißer abschwächt.
Allerdings ist diese Transformation nur für positive Werte definiert und erfordert
zusätzliche Prüfungen des Wertebereichs.

Die quadratische Transformation hingegen ist für alle numerischen Werte definiert
und eignet sich besonders gut, um funktionale Abbildungen unabhängig von
Sonderfällen zu demonstrieren.
Dadurch konnte der Fokus im Projekt gezielt auf den Vergleich funktionaler
Programmierkonzepte gelegt werden, ohne die Darstellung durch zusätzliche
Randfallbehandlung zu verkomplizieren.

\subsection{Wiederverwendung funktionaler Konzepte}

Die funktionalen Konzepte würden in zukünftigen Projekten erneut
eingesetzt werden, insbesondere bei:

\begin{itemize}
    \item Datenfiltern
    \item Aggregationen
    \item Transformationen von Listen und Datensätzen
\end{itemize}

\subsection{Grenzen funktionaler Elemente in Python}

Obwohl Python zahlreiche funktionale Sprachelemente bereitstellt, handelt es sich
nicht um eine rein funktionale Programmiersprache.
Im Vergleich zu funktionalen Sprachen wie Haskell werden zentrale Konzepte wie
Immutabilität oder Nebenwirkungsfreiheit nicht erzwungen, sondern lediglich
konventionell eingehalten.

Variablen können weiterhin verändert werden, und Funktionen können unbeabsichtigt
Seiteneffekte erzeugen.
Die korrekte Anwendung funktionaler Konzepte hängt somit stark von der Disziplin
der Entwickelnden ab und wird nicht durch den Sprachkern abgesichert.

Diese Einschränkungen wurden im Projekt bewusst in Kauf genommen, da der Fokus
auf dem Vergleich imperativer und funktionaler Denkweisen innerhalb einer
praxisnahen Sprache lag.

In einer rein funktionalen Sprache könnten diese Konzepte konsistenter und
durch den Compiler abgesichert umgesetzt werden.
Python eignet sich jedoch besonders gut, um funktionale Programmierkonzepte
schrittweise in bestehende imperative Arbeitsweisen zu integrieren.


\subsection{Anwendungsfälle im beruflichen Umfeld}

Im betrieblichen Kontext eignen sich funktionale Sprachelemente besonders
für:

\begin{itemize}
    \item Datenanalyse
    \item Reporting
    \item Verarbeitung von Log- oder Kundendaten
    \item Automatisierte Auswertungen
\end{itemize}

Zusammenfassend lässt sich sagen, dass funktionale Programmieransätze
eine sinnvolle Ergänzung zur imperativen Programmierung darstellen und
in vielen Anwendungsfällen zu einer klareren und effizienteren Lösung führen.

% ======================================================
\section{Ausführung des Programms}

Der vollständige Quellcode befindet sich im Projekt-Repository (vgl. \cite{github}).
Die Analysen wurden im Rahmen dieses Projekts primär in Jupyter Notebooks
durchgeführt, um Auswertungen und Ergebnisse nachvollziehbar zu dokumentieren.

Alternativ kann das Programm auch als Python-Skript ausgeführt werden.
Die notwendigen Schritte zur Ausführung sind im Repository dokumentiert.


% ======================================================
\section{Hinweis zur Entstehung der Arbeit}

Zur Unterstützung bei der Dokumentation und beim Refactoring wurden
KI-basierte Werkzeuge konsultiert.
Die Projektarbeit wurde eigenständig umgesetzt; sämtliche Ergebnisse,
Implementierungen und Auswertungen wurden von den Autoren geprüft,
verstanden und verantwortet.

% ======================================================
\section{Quellen}
\label{sec:quellen}

\begin{thebibliography}{9}

\bibitem{moro2011}
S. Moro, R. Laureano, P. Cortez.
\textit{Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology}.
Proceedings of the European Simulation and Modelling Conference (ESM 2011).

\bibitem{unibas-assignment}
Maringer, Dietmar und Kitzing, Emil.
\textit{Multivariate Datenanalyse – Assignment 1}.
WWZ, Universität Basel, Herbstsemester 2024.

\bibitem{montgomery2017}
Montgomery, Douglas C.
\textit{Design and Analysis of Experiments}.
9th Edition, Wiley, 2022.

\bibitem{github}
Projekt-Repository:
\href{https://github.com/stoicfist/Modul-323-Projektarbeit}{https://github.com/stoicfist/Modul-323-Projektarbeit}

\end{thebibliography}


\vspace{1em}
\newline
\textit{Hinweis:} Der vollständige Quellcode wurde in dieser Dokumentation bewusst
nicht vollständig abgedruckt, um den Fokus auf Konzept und Vergleich zu legen
(vgl. \cite{github}).

\section{Appendix}

\subsection{Projekt-Repository}

Der vollständige Quellcode des Projekts ist im öffentlichen GitHub-Repository
verfügbar (vgl. \cite{github}).

\subsection{Weitere Beispielausgaben}
\label{sec:appendix-output}

\subsubsection{Menüoption 7: Vergleich zweier Gruppen}
\begin{verbatim}
Verfügbare Gruppen in 'education': primary, secondary, tertiary

========================================================================
                        VERGLEICH ZWEIER GRUPPEN
========================================================================
education | count | avg(age) | avg(balance) | avg(duration) | success
----------+-------+----------+--------------+---------------+--------
tertiary  |  2657 |     39.7 |      2404.61 |         382.4 |   62.5%
secondary |  3815 |     40.7 |      1709.54 |         387.2 |   52.2%

Δ Erfolgsquote (A-B): +10.3%
\end{verbatim}

\subsubsection{Menüoption 8: ANOVA-Auswertung}
\begin{verbatim}
========================================================================
                    ANOVA-ÄHNLICHER F-WERT (BALANCE)
========================================================================
F(2, 7471) = 41.928

Interpretation: Deutliche Unterschiede der Mittelwerte zwischen Gruppen möglich
(hoher F-Wert).
\end{verbatim}

\subsubsection{Menüoption 1: Erfolgsquote gesamt}
\begin{verbatim}
========================================================================
                              ERFOLGSQUOTE
========================================================================
Metric |  Value
-------+-------
Total  |   7474
Yes    |   4137
Quote  |  55.4%
\end{verbatim}

\subsection{Interaktive Konsolen-Ausführung (CLI)}

Neben der Ausführung im Jupyter Notebook kann das Programm auch direkt als
Python-Skript gestartet werden. Dabei wird eine textbasierte Benutzeroberfläche
angezeigt, welche die Bedienung über ein Menü ermöglicht:

\begin{verbatim}
========================================================================
                          BANK MARKETING – CLI
========================================================================
                        Datensätze geladen: 7474
========================================================================
                                  MENU
========================================================================
1) Erfolgsquote gesamt
2) Filter setzen (housing/loan/balance>X)
3) Transformationen (log(balance), balance^2+1)
4) duration Analyse + optional Buckets
5) Group by education
6) Group by marital
7) Vergleich zweier Gruppen
8) ANOVA-ähnlicher F-Wert (balance)
q) Quit
Auswahl: 7
========================================================================
                        VERGLEICH ZWEIER GRUPPEN
========================================================================
Gruppierungsfeld (education/marital/job) [Default: education]:
Verfügbare Gruppen:
primary, secondary, tertiary
Gruppe A: secondary
Gruppe B: tertiary
education | count | avg(age) | avg(balance) | avg(duration) | success
----------+-------+----------+--------------+---------------+--------
secondary |  3815 |     40.7 |      1709.54 |         387.2 |   52.2%
tertiary  |  2657 |     39.7 |      2404.61 |         382.4 |   62.5%
Δ Erfolgsquote (A-B): -10.3%
\end{verbatim}



\end{document}
